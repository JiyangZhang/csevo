
My ssh-config: (please also add this on seoul because we need to transfer files from seoul)

Host tacc-maverick2
     HostName login1.maverick2.tacc.utexas.edu
     User pynie
     IdentityFile ~/.ssh/tacc.maverick2.key


# ========== Download repo

ssh tacc-maverick2

cd $WORK
mkdir -p projects
git clone ssh://gligoric@cozy.ece.utexas.edu:2002//home/repos/projects/senl/nlpast

cd nlpast
./update-repos.sh

cd csevo-data
mkdir -p models-data


# ========== Get dataset and miniconda installation package

cd $WORK
wget http://cozy.ece.utexas.edu/~pynie/nlpast-tacc.tar
tar xf nlpast-tacc.tar
mv models-data/DeepCom/ $WORK/projects/nlpast/csevo-data/models-data/


# ========== Install miniconda

./Miniconda3-latest-Linux-x86_64.sh
# Change installation directory: $WORK/miniconda3
# Do not run conda init

echo "source $WORK/miniconda3/etc/profile.d/conda.sh" >> ~/.bashrc

exit
ssh tacc-maverick2  # logout and re-login to have conda scripts loaded

cd $WORK/projects/nlpast/python/envs
conda env create -n csevo -f csevo.yaml  # May take several minutes
conda env create -n DeepCom -f DeepCom.yaml  # May take several minutes


# ========== Process data and start training jobs

cd $WORK/projects/nlpast/python
conda activate csevo

./run.sh prepare_comment_generation_tacc  # May take several minutes
./run.sh train_comment_generation_tacc_16_27

# ========== Check status

# Current jobs status
showq

# Check $WORK/projects/nlpast/ml-logs/csevo-train/*.stderr (the 3 ones
# with the largest numbers) to see if there is any unexpected
# exception

# Check training logs
cd $WORK/projects/nlpast/csevo-data/models-work
find -name log-train.txt | xargs tail
